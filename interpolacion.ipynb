from google.colab import drive
drive.mount('/content/drive')

# Importar las librerías necesarias
import pandas as pd
import numpy as np
from scipy.interpolate import griddata

# Funciones del script de integración
def load_and_validate_data(file_paths):
    dataframes = {}
    required_columns = ['id_punto', 'longitud', 'latitud']
    for source, path in file_paths.items():
        try:
            df = pd.read_csv(path)
            if not all(col in df.columns for col in required_columns):
                raise ValueError(f"Faltan columnas requeridas en {source}")
            dataframes[source] = df
            print(f"Datos de {source} cargados exitosamente: {df.shape[0]} registros")
        except Exception as e:
            print(f"Error al cargar {source}: {str(e)}")
    return dataframes

def interpolate_spatial_resolution(df, target_res=500):  # Usar 500 metros para reducir el tamaño del grid
    x = np.arange(df['longitud'].min(), df['longitud'].max(), target_res / 111111.0)
    y = np.arange(df['latitud'].min(), df['latitud'].max(), target_res / 111111.0)
    xi, yi = np.meshgrid(x, y)
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    numeric_cols = [col for col in numeric_cols if col not in ['longitud', 'latitud', 'id_punto']]
    interpolated_data = []
    for col in numeric_cols:
        zi = griddata((df['longitud'], df['latitud']), df[col], (xi, yi), method='linear')
        interpolated_data.append(zi)
    new_points = []
    for i in range(len(x)):
        for j in range(len(y)):
            point = {'longitud': xi[i,j], 'latitud': yi[i,j]}
            for k, col in enumerate(numeric_cols):
                point[col] = interpolated_data[k][i,j]
            new_points.append(point)
    return pd.DataFrame(new_points)

def integrate_datasets(file_paths, target_resolution=500, temporal_freq='M'):
    datasets = load_and_validate_data(file_paths)
    interpolated_datasets = {}
    for source, df in datasets.items():
        interpolated_datasets[source] = interpolate_spatial_resolution(df, target_resolution)
        print(f"Interpolación espacial completada para {source}")
    merged_df = None
    for source, df in interpolated_datasets.items():
        if merged_df is None:
            merged_df = df
        else:
            merged_df = merged_df.merge(df, on=['longitud', 'latitud'], how='outer', suffixes=(f'_{source}', ''))
    return merged_df

# Configurar las rutas de archivos en Google Drive
file_paths = {
    'era5': '/content/drive/MyDrive/data/era5_mexico_data.csv',
    'modis': '/content/drive/MyDrive/data/modis_mexico_data.csv',
    'srtm': '/content/drive/MyDrive/data/srtm_mexico_data.csv',
    'chirps': '/content/drive/MyDrive/data/variables_mexico_completo.csv'
}

# Integrar y guardar el resultado
resultado = integrate_datasets(file_paths, target_resolution=500, temporal_freq='M')
resultado.to_csv('/content/drive/MyDrive/data/datos_consolidados_mexico.csv', index=False)
print("Integración completada y archivo guardado como 'datos_consolidados_mexico.csv'")
